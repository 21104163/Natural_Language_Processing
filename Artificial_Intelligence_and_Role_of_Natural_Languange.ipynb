{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LINK: https://www.datasciencecentral.com/overview-of-artificial-intelligence-and-role-of-natural-language/"
      ],
      "metadata": {
        "id": "J5UoYPRgp8m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "documents = [\"Stage 1 – Machine Learning – It is a set of algorithms used by intelligent systems to learn from experience.\"\n",
        "             ,\"Stage 2 – Machine Intelligence – These are the advanced set of algorithms used by machines to learn from experience. Eg – Deep Neural Networks.\"\n",
        "             ,\"Stage 3 – Machine Consciousness – It is self-learning from experience without the need of external data.\"\n",
        "             ,\"ANI – Artificial Narrow Intelligence – It comprises of basic/role tasks such as those performed by chatbots, personal assistants like SIRI by Apple and Alexa by Amazon.\"\n",
        "             ,\"AGI – Artificial General Intelligence – Artificial General Intelligence comprises of human-level tasks such as performed by self-driving cars by Uber, Autopilot by Tesla. It involves continual learning by the machines.\"\n",
        "             ,\"ASI – Artificial Super Intelligence – Artificial Super Intelligence refers to intelligence way smarter than humans.\"\n",
        "             ,\"AI or Artificial Intelligence – Building systems that can do intelligent things.\"\n",
        "             ,\"NLP or Natural Language Processing – Building systems that can understand language. It is a subset of Artificial Intelligence.\"\n",
        "             ,\"ML or Machine Learning – Building systems that can learn from experience. It is also a subset of Artificial Intelligence.\"\n",
        "             ,\"NN or Neural Network – Biologically inspired network of Artificial Neurons.\"\n",
        "             ,\"DL or Deep Learning – Building systems that use Deep Neural Network on a large set of data. It is a subset of Machine Learning.\"\n",
        "             ,\"Natural Language Processing (NLP) is “ability of machines to understand and interpret human language the way it is written or spoken”.\"\n",
        "             ,\"With NLP, it is possible to perform certain tasks like Automated Speech and Automated Text Writing in less time.\"]"
      ],
      "metadata": {
        "id": "dwoXcOR8nim3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "for document in documents:\n",
        "    text = []\n",
        "    doc = nlp(document)\n",
        "    for w in doc:\n",
        "        if not w.is_stop and not w.is_punct and not w.like_num:\n",
        "            text.append(w.lemma_)\n",
        "    texts.append(text)\n",
        "print(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH6b79tJnxxu",
        "outputId": "26e9d6f9-cf30-481b-d78d-c148512a1b53"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['stage', 'Machine', 'Learning', 'set', 'algorithm', 'intelligent', 'system', 'learn', 'experience'], ['stage', 'Machine', 'Intelligence', 'advanced', 'set', 'algorithm', 'machine', 'learn', 'experience', 'eg', 'Deep', 'Neural', 'Networks'], ['stage', 'Machine', 'Consciousness', 'self', 'learn', 'experience', 'need', 'external', 'datum'], ['ANI', 'Artificial', 'Narrow', 'Intelligence', 'comprise', 'basic', 'role', 'task', 'perform', 'chatbot', 'personal', 'assistant', 'like', 'siri', 'Apple', 'Alexa', 'Amazon'], ['AGI', 'Artificial', 'General', 'Intelligence', 'Artificial', 'General', 'Intelligence', 'comprise', 'human', 'level', 'task', 'perform', 'self', 'drive', 'car', 'Uber', 'Autopilot', 'Tesla', 'involve', 'continual', 'learning', 'machine'], ['ASI', 'Artificial', 'Super', 'Intelligence', 'Artificial', 'Super', 'Intelligence', 'refer', 'intelligence', 'way', 'smart', 'human'], ['AI', 'Artificial', 'Intelligence', 'building', 'system', 'intelligent', 'thing'], ['NLP', 'Natural', 'Language', 'Processing', 'building', 'system', 'understand', 'language', 'subset', 'Artificial', 'Intelligence'], ['ML', 'Machine', 'Learning', 'building', 'system', 'learn', 'experience', 'subset', 'Artificial', 'Intelligence'], ['NN', 'Neural', 'Network', 'biologically', 'inspire', 'network', 'Artificial', 'Neurons'], ['DL', 'Deep', 'Learning', 'building', 'system', 'use', 'Deep', 'Neural', 'Network', 'large', 'set', 'datum', 'subset', 'Machine', 'Learning'], ['Natural', 'Language', 'Processing', 'NLP', 'ability', 'machine', 'understand', 'interpret', 'human', 'language', 'way', 'write', 'speak'], ['NLP', 'possible', 'perform', 'certain', 'task', 'like', 'Automated', 'Speech', 'Automated', 'Text', 'write', 'time']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  dictionary = corpora.Dictionary(texts)\n",
        "print(dictionary.token2id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGBEZ2Psn0Kc",
        "outputId": "0492d4d0-f49d-45f3-eb78-b7f483f5842f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Learning': 0, 'Machine': 1, 'algorithm': 2, 'experience': 3, 'intelligent': 4, 'learn': 5, 'set': 6, 'stage': 7, 'system': 8, 'Deep': 9, 'Intelligence': 10, 'Networks': 11, 'Neural': 12, 'advanced': 13, 'eg': 14, 'machine': 15, 'Consciousness': 16, 'datum': 17, 'external': 18, 'need': 19, 'self': 20, 'ANI': 21, 'Alexa': 22, 'Amazon': 23, 'Apple': 24, 'Artificial': 25, 'Narrow': 26, 'assistant': 27, 'basic': 28, 'chatbot': 29, 'comprise': 30, 'like': 31, 'perform': 32, 'personal': 33, 'role': 34, 'siri': 35, 'task': 36, 'AGI': 37, 'Autopilot': 38, 'General': 39, 'Tesla': 40, 'Uber': 41, 'car': 42, 'continual': 43, 'drive': 44, 'human': 45, 'involve': 46, 'learning': 47, 'level': 48, 'ASI': 49, 'Super': 50, 'intelligence': 51, 'refer': 52, 'smart': 53, 'way': 54, 'AI': 55, 'building': 56, 'thing': 57, 'Language': 58, 'NLP': 59, 'Natural': 60, 'Processing': 61, 'language': 62, 'subset': 63, 'understand': 64, 'ML': 65, 'NN': 66, 'Network': 67, 'Neurons': 68, 'biologically': 69, 'inspire': 70, 'network': 71, 'DL': 72, 'large': 73, 'use': 74, 'ability': 75, 'interpret': 76, 'speak': 77, 'write': 78, 'Automated': 79, 'Speech': 80, 'Text': 81, 'certain': 82, 'possible': 83, 'time': 84}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJLAnj-an4at",
        "outputId": "aa4e722a-622c-4d85-f3b2-6c56993b4eb8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)],\n",
              " [(1, 1),\n",
              "  (2, 1),\n",
              "  (3, 1),\n",
              "  (5, 1),\n",
              "  (6, 1),\n",
              "  (7, 1),\n",
              "  (9, 1),\n",
              "  (10, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (13, 1),\n",
              "  (14, 1),\n",
              "  (15, 1)],\n",
              " [(1, 1), (3, 1), (5, 1), (7, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1)],\n",
              " [(10, 1),\n",
              "  (21, 1),\n",
              "  (22, 1),\n",
              "  (23, 1),\n",
              "  (24, 1),\n",
              "  (25, 1),\n",
              "  (26, 1),\n",
              "  (27, 1),\n",
              "  (28, 1),\n",
              "  (29, 1),\n",
              "  (30, 1),\n",
              "  (31, 1),\n",
              "  (32, 1),\n",
              "  (33, 1),\n",
              "  (34, 1),\n",
              "  (35, 1),\n",
              "  (36, 1)],\n",
              " [(10, 2),\n",
              "  (15, 1),\n",
              "  (20, 1),\n",
              "  (25, 2),\n",
              "  (30, 1),\n",
              "  (32, 1),\n",
              "  (36, 1),\n",
              "  (37, 1),\n",
              "  (38, 1),\n",
              "  (39, 2),\n",
              "  (40, 1),\n",
              "  (41, 1),\n",
              "  (42, 1),\n",
              "  (43, 1),\n",
              "  (44, 1),\n",
              "  (45, 1),\n",
              "  (46, 1),\n",
              "  (47, 1),\n",
              "  (48, 1)],\n",
              " [(10, 2),\n",
              "  (25, 2),\n",
              "  (45, 1),\n",
              "  (49, 1),\n",
              "  (50, 2),\n",
              "  (51, 1),\n",
              "  (52, 1),\n",
              "  (53, 1),\n",
              "  (54, 1)],\n",
              " [(4, 1), (8, 1), (10, 1), (25, 1), (55, 1), (56, 1), (57, 1)],\n",
              " [(8, 1),\n",
              "  (10, 1),\n",
              "  (25, 1),\n",
              "  (56, 1),\n",
              "  (58, 1),\n",
              "  (59, 1),\n",
              "  (60, 1),\n",
              "  (61, 1),\n",
              "  (62, 1),\n",
              "  (63, 1),\n",
              "  (64, 1)],\n",
              " [(0, 1),\n",
              "  (1, 1),\n",
              "  (3, 1),\n",
              "  (5, 1),\n",
              "  (8, 1),\n",
              "  (10, 1),\n",
              "  (25, 1),\n",
              "  (56, 1),\n",
              "  (63, 1),\n",
              "  (65, 1)],\n",
              " [(12, 1), (25, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1)],\n",
              " [(0, 2),\n",
              "  (1, 1),\n",
              "  (6, 1),\n",
              "  (8, 1),\n",
              "  (9, 2),\n",
              "  (12, 1),\n",
              "  (17, 1),\n",
              "  (56, 1),\n",
              "  (63, 1),\n",
              "  (67, 1),\n",
              "  (72, 1),\n",
              "  (73, 1),\n",
              "  (74, 1)],\n",
              " [(15, 1),\n",
              "  (45, 1),\n",
              "  (54, 1),\n",
              "  (58, 1),\n",
              "  (59, 1),\n",
              "  (60, 1),\n",
              "  (61, 1),\n",
              "  (62, 1),\n",
              "  (64, 1),\n",
              "  (75, 1),\n",
              "  (76, 1),\n",
              "  (77, 1),\n",
              "  (78, 1)],\n",
              " [(31, 1),\n",
              "  (32, 1),\n",
              "  (36, 1),\n",
              "  (59, 1),\n",
              "  (78, 1),\n",
              "  (79, 2),\n",
              "  (80, 1),\n",
              "  (81, 1),\n",
              "  (82, 1),\n",
              "  (83, 1),\n",
              "  (84, 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpora.MmCorpus.serialize('/tmp/example.mm', corpus)"
      ],
      "metadata": {
        "id": "ocSkBh4qn7X3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import models\n",
        "tfidf = models.TfidfModel(corpus)\n",
        "\n",
        "for document in tfidf[corpus]:\n",
        "       print(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DSKCn5jn-8i",
        "outputId": "8466feee-174e-4104-a0f0-f13623de4ab1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0.34502354858412315), (1, 0.22482821753076257), (2, 0.4404279500711812), (3, 0.2773330484844279), (4, 0.4404279500711812), (5, 0.2773330484844279), (6, 0.34502354858412315), (7, 0.34502354858412315), (8, 0.22482821753076257)]\n",
            "[(1, 0.15218811594119952), (2, 0.2981293925883948), (3, 0.1877290786744746), (5, 0.1877290786744746), (6, 0.23354934888090742), (7, 0.23354934888090742), (9, 0.2981293925883948), (10, 0.09859684183936654), (11, 0.40852970650231507), (12, 0.23354934888090742), (13, 0.40852970650231507), (14, 0.40852970650231507), (15, 0.23354934888090742)]\n",
            "[(1, 0.16738703067612137), (3, 0.20647744310748456), (5, 0.20647744310748456), (7, 0.2568737498571894), (16, 0.44932926655607364), (17, 0.32790335483177907), (18, 0.44932926655607364), (19, 0.44932926655607364), (20, 0.32790335483177907)]\n",
            "[(10, 0.0673654674848933), (21, 0.2791245048683349), (22, 0.2791245048683349), (23, 0.2791245048683349), (24, 0.2791245048683349), (25, 0.0673654674848933), (26, 0.2791245048683349), (27, 0.2791245048683349), (28, 0.2791245048683349), (29, 0.2791245048683349), (30, 0.20369441381727665), (31, 0.20369441381727665), (32, 0.15957063912642513), (33, 0.2791245048683349), (34, 0.2791245048683349), (35, 0.2791245048683349), (36, 0.15957063912642513)]\n",
            "[(10, 0.11763033325235936), (15, 0.13931728048901768), (20, 0.17784068509836598), (25, 0.11763033325235936), (30, 0.17784068509836598), (32, 0.13931728048901768), (36, 0.13931728048901768), (37, 0.2436968802593476), (38, 0.2436968802593476), (39, 0.4873937605186952), (40, 0.2436968802593476), (41, 0.2436968802593476), (42, 0.2436968802593476), (43, 0.2436968802593476), (44, 0.2436968802593476), (45, 0.13931728048901768), (46, 0.2436968802593476), (47, 0.2436968802593476), (48, 0.2436968802593476)]\n",
            "[(10, 0.15806534813164957), (25, 0.15806534813164957), (45, 0.18720710748993447), (49, 0.3274668289356231), (50, 0.6549336578712462), (51, 0.3274668289356231), (52, 0.3274668289356231), (53, 0.3274668289356231), (54, 0.2389727974478935)]\n",
            "[(4, 0.42139944123567136), (8, 0.21511460665964366), (10, 0.13936450109122273), (25, 0.13936450109122273), (55, 0.5774478945319186), (56, 0.2653509879394241), (57, 0.5774478945319186)]\n",
            "[(8, 0.19153505510061863), (10, 0.12408821423182938), (25, 0.12408821423182938), (56, 0.23626483057189798), (58, 0.3752082038954645), (59, 0.29393154077747785), (60, 0.3752082038954645), (61, 0.3752082038954645), (62, 0.3752082038954645), (63, 0.29393154077747785), (64, 0.3752082038954645)]\n",
            "[(0, 0.34913420576949605), (1, 0.22750685129839968), (3, 0.28063723190371104), (5, 0.28063723190371104), (8, 0.22750685129839968), (10, 0.14739296098196902), (25, 0.14739296098196902), (56, 0.28063723190371104), (63, 0.34913420576949605), (65, 0.6107133044745182)]\n",
            "[(12, 0.23500734792675962), (25, 0.09921236100914653), (66, 0.4110800708049207), (67, 0.299990551148747), (68, 0.4110800708049207), (69, 0.4110800708049207), (70, 0.4110800708049207), (71, 0.4110800708049207)]\n",
            "[(0, 0.3817207922957124), (1, 0.1243706490157882), (6, 0.1908603961478562), (8, 0.1243706490157882), (9, 0.4872725549901323), (12, 0.1908603961478562), (17, 0.24363627749506614), (56, 0.15341531242098605), (63, 0.1908603961478562), (67, 0.24363627749506614), (72, 0.33385724256914623), (73, 0.33385724256914623), (74, 0.33385724256914623)]\n",
            "[(15, 0.20590878659147657), (45, 0.20590878659147657), (54, 0.26284578299737976), (58, 0.26284578299737976), (59, 0.20590878659147657), (60, 0.26284578299737976), (61, 0.26284578299737976), (62, 0.26284578299737976), (64, 0.26284578299737976), (75, 0.36018022124890847), (76, 0.36018022124890847), (77, 0.36018022124890847), (78, 0.26284578299737976)]\n",
            "[(31, 0.21957714226608957), (32, 0.17201289064502603), (36, 0.17201289064502603), (59, 0.17201289064502603), (78, 0.21957714226608957), (79, 0.6017775349539589), (80, 0.30088876747697946), (81, 0.30088876747697946), (82, 0.30088876747697946), (83, 0.30088876747697946), (84, 0.30088876747697946)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "bigram = gensim.models.Phrases(texts)\n",
        "texts = [bigram[line] for line in texts]\n",
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XlDCeD_oGch",
        "outputId": "9af63f65-21c2-4ae3-ff87-d26248ea4c11"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['stage',\n",
              "  'Machine',\n",
              "  'Learning',\n",
              "  'set',\n",
              "  'algorithm',\n",
              "  'intelligent',\n",
              "  'system',\n",
              "  'learn',\n",
              "  'experience'],\n",
              " ['stage',\n",
              "  'Machine',\n",
              "  'Intelligence',\n",
              "  'advanced',\n",
              "  'set',\n",
              "  'algorithm',\n",
              "  'machine',\n",
              "  'learn',\n",
              "  'experience',\n",
              "  'eg',\n",
              "  'Deep',\n",
              "  'Neural',\n",
              "  'Networks'],\n",
              " ['stage',\n",
              "  'Machine',\n",
              "  'Consciousness',\n",
              "  'self',\n",
              "  'learn',\n",
              "  'experience',\n",
              "  'need',\n",
              "  'external',\n",
              "  'datum'],\n",
              " ['ANI',\n",
              "  'Artificial',\n",
              "  'Narrow',\n",
              "  'Intelligence',\n",
              "  'comprise',\n",
              "  'basic',\n",
              "  'role',\n",
              "  'task',\n",
              "  'perform',\n",
              "  'chatbot',\n",
              "  'personal',\n",
              "  'assistant',\n",
              "  'like',\n",
              "  'siri',\n",
              "  'Apple',\n",
              "  'Alexa',\n",
              "  'Amazon'],\n",
              " ['AGI',\n",
              "  'Artificial',\n",
              "  'General',\n",
              "  'Intelligence',\n",
              "  'Artificial',\n",
              "  'General',\n",
              "  'Intelligence',\n",
              "  'comprise',\n",
              "  'human',\n",
              "  'level',\n",
              "  'task',\n",
              "  'perform',\n",
              "  'self',\n",
              "  'drive',\n",
              "  'car',\n",
              "  'Uber',\n",
              "  'Autopilot',\n",
              "  'Tesla',\n",
              "  'involve',\n",
              "  'continual',\n",
              "  'learning',\n",
              "  'machine'],\n",
              " ['ASI',\n",
              "  'Artificial',\n",
              "  'Super',\n",
              "  'Intelligence',\n",
              "  'Artificial',\n",
              "  'Super',\n",
              "  'Intelligence',\n",
              "  'refer',\n",
              "  'intelligence',\n",
              "  'way',\n",
              "  'smart',\n",
              "  'human'],\n",
              " ['AI',\n",
              "  'Artificial',\n",
              "  'Intelligence',\n",
              "  'building',\n",
              "  'system',\n",
              "  'intelligent',\n",
              "  'thing'],\n",
              " ['NLP',\n",
              "  'Natural',\n",
              "  'Language',\n",
              "  'Processing',\n",
              "  'building',\n",
              "  'system',\n",
              "  'understand',\n",
              "  'language',\n",
              "  'subset',\n",
              "  'Artificial',\n",
              "  'Intelligence'],\n",
              " ['ML',\n",
              "  'Machine',\n",
              "  'Learning',\n",
              "  'building',\n",
              "  'system',\n",
              "  'learn',\n",
              "  'experience',\n",
              "  'subset',\n",
              "  'Artificial',\n",
              "  'Intelligence'],\n",
              " ['NN',\n",
              "  'Neural',\n",
              "  'Network',\n",
              "  'biologically',\n",
              "  'inspire',\n",
              "  'network',\n",
              "  'Artificial',\n",
              "  'Neurons'],\n",
              " ['DL',\n",
              "  'Deep',\n",
              "  'Learning',\n",
              "  'building',\n",
              "  'system',\n",
              "  'use',\n",
              "  'Deep',\n",
              "  'Neural',\n",
              "  'Network',\n",
              "  'large',\n",
              "  'set',\n",
              "  'datum',\n",
              "  'subset',\n",
              "  'Machine',\n",
              "  'Learning'],\n",
              " ['Natural',\n",
              "  'Language',\n",
              "  'Processing',\n",
              "  'NLP',\n",
              "  'ability',\n",
              "  'machine',\n",
              "  'understand',\n",
              "  'interpret',\n",
              "  'human',\n",
              "  'language',\n",
              "  'way',\n",
              "  'write',\n",
              "  'speak'],\n",
              " ['NLP',\n",
              "  'possible',\n",
              "  'perform',\n",
              "  'certain',\n",
              "  'task',\n",
              "  'like',\n",
              "  'Automated',\n",
              "  'Speech',\n",
              "  'Automated',\n",
              "  'Text',\n",
              "  'write',\n",
              "  'time']]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]"
      ],
      "metadata": {
        "id": "n314OPW5oLqa"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary.filter_extremes(no_below=20, no_above=0.5)"
      ],
      "metadata": {
        "id": "9Hw7QxKEoTv_"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}